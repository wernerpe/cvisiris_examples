{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiments with b = 2:\n",
      "  Experiments with N = 1000:\n",
      "    Experiment data: [38, 1.4798, 669.254762172699, 4.333, 39.987, 439.079, 185.857]\n",
      "    Experiment data: [36, 1.4496, 544.01407122612, 4.037, 40.953, 306.65, 192.374]\n",
      "    Experiment data: [35, 1.4409999999999998, 469.2104163169861, 3.931, 42.474999999999994, 242.69, 180.11599999999999]\n",
      "    Experiment data: [36, 1.4818, 554.8998708724976, 4.613, 40.102000000000004, 329.172, 181.01299999999998]\n",
      "    Experiment data: [36, 1.4694, 616.4663352966309, 4.203, 39.327, 402.71999999999997, 170.215]\n",
      "    Experiment data: [36, 1.4582, 486.2716007232666, 4.125, 40.04, 265.565, 176.542]\n",
      "    Experiment data: [34, 1.4436, 542.9091618061066, 3.9939999999999998, 41.372, 327.405, 170.138]\n",
      "    Experiment data: [33, 1.4180000000000001, 481.6702198982239, 3.8970000000000002, 39.925, 256.695, 181.154]\n",
      "    Experiment data: [32, 1.42, 647.4932613372803, 3.878, 39.385000000000005, 419.081, 185.149]\n",
      "    Experiment data: [35, 1.4542000000000002, 522.3782551288605, 4.0520000000000005, 40.513999999999996, 294.702, 183.109]\n",
      "Experiments with b = 3:\n",
      "  Experiments with N = 1500:\n",
      "    Experiment data: [44, 1.9325999999999999, 4278.822318553925, 7.312, 372.164, 2710.425, 1188.92]\n",
      "    Experiment data: [47, 1.9592, 4890.672221660614, 7.555, 369.081, 3300.3859999999995, 1213.65]\n",
      "    Experiment data: [45, 1.9558, 5212.3662695884705, 7.606999999999999, 369.779, 3603.968, 1231.013]\n",
      "    Experiment data: [44, 1.9664, 7924.023255109787, 7.3149999999999995, 365.625, 6154.992, 1396.094]\n",
      "    Experiment data: [59, 2.612, 9641.711630105972, 12.548000000000002, 482.41900000000004, 7637.423, 1509.323]\n",
      "    Experiment data: [43, 1.92, 5479.276831150055, 7.489999999999999, 373.804, 3741.759, 1356.2240000000002]\n",
      "    Experiment data: [45, 1.9678, 4572.9343085289, 7.645, 370.496, 3079.89, 1114.904]\n",
      "    Experiment data: [45, 1.9666, 4608.326617240906, 7.478999999999999, 377.102, 2857.662, 1366.0839999999998]\n",
      "    Experiment data: [48, 1.9922, 6745.576708078384, 7.897, 367.266, 4750.661, 1619.7530000000002]\n",
      "    Experiment data: [43, 1.9236000000000002, 3909.040205478668, 7.818, 367.922, 2181.7430000000004, 1351.556]\n",
      "Experiments with b = 6:\n",
      "  Experiments with N = 100:\n",
      "    Experiment data: [3, 0.7706, 17.026009798049927, 0.06, 0.373, 0.149, 16.444]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-e17e2b9265f6>:120: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  np.sum(len(g) for g in data['rb']), coverage , data['ttotal'], tsample, tvis, tmhs, tregions])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "def parse_logfile(filename):\n",
    "    logfile = open(filename, 'r')\n",
    "    lines = logfile.readlines()\n",
    "    logfile.close()\n",
    "\n",
    "    iteration_data = []\n",
    "    current_iteration = {}\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith('ITERATION:'):\n",
    "            if current_iteration:\n",
    "                iteration_data.append(current_iteration)\n",
    "                current_iteration = {}\n",
    "        elif line.startswith('summary'):\n",
    "            current_iteration['summary'] = line.strip()\n",
    "        elif line.startswith('number of regions step'):\n",
    "            current_iteration['number_of_regions_step'] = int(line.split()[-1])\n",
    "        elif line.startswith('number of regions total'):\n",
    "            current_iteration['number_of_regions_total'] = int(line.split()[-1])\n",
    "        elif line.startswith('tstep'):\n",
    "            a = line.replace(',', '')\n",
    "            current_iteration['tstep'] = float(a.split()[1])\n",
    "            current_iteration['t_total'] = float(a.split()[3])\n",
    "        elif line.startswith('tsample'):\n",
    "            a = line.replace(',', '')\n",
    "            current_iteration['tsample'] = float(a.split()[1])\n",
    "            current_iteration['t_visgraph'] = float(a.split()[3])\n",
    "            current_iteration['t_mhs'] = float(a.split()[5])\n",
    "            current_iteration['t_regions'] = float(a.split()[7])\n",
    "\n",
    "        # elif line.startswith('t_mhs'):\n",
    "        #     current_iteration['t_mhs'] = float(line.split()[1])\n",
    "        # elif line.startswith('t_regions'):\n",
    "        #     current_iteration['t_regions'] = float(line.split()[1])\n",
    "        elif line.startswith('coverage'):\n",
    "            current_iteration['coverage'] = float(line.split()[1])\n",
    "        elif '[VisSeeder] Coverage met, terminated' in line:\n",
    "            current_iteration['termination'] = line.strip()\n",
    "\n",
    "    if current_iteration:\n",
    "        iteration_data.append(current_iteration)\n",
    "    return iteration_data\n",
    "\n",
    "\n",
    "logs_directory = 'logs'\n",
    "\n",
    "# Get a list of all subdirectories in the logs directory\n",
    "experiment_directories = [directory for directory in glob.glob(os.path.join(logs_directory, '*')) if os.path.isdir(directory)]\n",
    "\n",
    "# Define a dictionary to store the grouped experiments\n",
    "grouped_experiments = {}\n",
    "\n",
    "# Iterate over each experiment directory\n",
    "for experiment_directory in experiment_directories:\n",
    "    # Parse the experiment name\n",
    "    experiment_name = os.path.basename(experiment_directory)\n",
    "    name_parts = experiment_name.split('_')\n",
    "    \n",
    "    # Extract the relevant values from the experiment name\n",
    "    if '3dof' in experiment_name and not 'cvx_hull' in experiment_name:\n",
    "        b = 1  #int(name_parts[-5])\n",
    "        # print(experiment_name)\n",
    "    if '3dof_flipper2' in experiment_name and not 'cvx_hull' in experiment_name:\n",
    "        b = 6  #int(name_parts[-5])\n",
    "        # print(experiment_name)\n",
    "    elif '5dof' in experiment_name and 'greedy' in experiment_name:\n",
    "        b = 2\n",
    "    elif '7dof_iiwa' in experiment_name and 'greedy' in experiment_name:\n",
    "        b = 3\n",
    "    else:\n",
    "        continue\n",
    "    N = int(name_parts[-2])\n",
    "    \n",
    "    # Get the last pickle file in the 'data' subdirectory\n",
    "    data_directory = os.path.join(experiment_directory, 'data')\n",
    "    pickle_files = glob.glob(os.path.join(data_directory, '*.pkl'))\n",
    "    pkl_files = os.listdir(data_directory)\n",
    "    pkl_idx = np.argsort([int(s.replace('it_', '').replace('.pkl', '')) for s in pkl_files])\n",
    "    \n",
    "    #pickle_files.sort()\n",
    "    \n",
    "    last_pickle_file = data_directory+'/'+pkl_files[pkl_idx[-1]]#pickle_files[-1]#max(pickle_files, key=os.path.getctime)\n",
    "    \n",
    "    # Load the last pickle file\n",
    "    with open(last_pickle_file, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    \n",
    "    # Find the 'summar' subdirectory and get the path to the text file\n",
    "    summar_directory = os.path.join(experiment_directory, 'summary')\n",
    "    text_files = glob.glob(os.path.join(summar_directory, '*.txt'))\n",
    "    last_text_file = max(text_files, key=os.path.getctime)\n",
    "    \n",
    "\n",
    "    iteration_dictionaries = parse_logfile(last_text_file)\n",
    "    tsample = np.sum([i['tsample'] for i in iteration_dictionaries[1:]])\n",
    "    tvis = np.sum([i['t_visgraph'] for i in iteration_dictionaries[1:]])\n",
    "    tmhs = np.sum([i['t_mhs'] for i in iteration_dictionaries[1:]])\n",
    "    tregions = np.sum([i['t_regions'] for i in iteration_dictionaries[1:]])\n",
    "    coverage = np.sum([i['coverage'] for i in iteration_dictionaries[1:]])\n",
    "    # # Read the last line of the text file to extract coverage\n",
    "    # with open(last_text_file, 'r') as file:\n",
    "    #     lines = file.readlines()\n",
    "    #     last_line = lines[-1].strip()\n",
    "    #     coverage = float(last_line.split()[1])\n",
    "\n",
    "    # Group experiments by 'b' value\n",
    "    if b not in grouped_experiments:\n",
    "        grouped_experiments[b] = {}\n",
    "    \n",
    "    # Group experiments by 'N' value\n",
    "    if N not in grouped_experiments[b]:\n",
    "        grouped_experiments[b][N] = []\n",
    "    \n",
    "    # Add the experiment data to the grouped experiments dictionary\n",
    "    grouped_experiments[b][N].append([\n",
    "            np.sum(len(g) for g in data['rb']), coverage , data['ttotal'], tsample, tvis, tmhs, tregions])\n",
    "\n",
    "# Print the grouped experiments\n",
    "for b, experiments in grouped_experiments.items():\n",
    "    print(f\"Experiments with b = {b}:\")\n",
    "    for N, experiment_data in experiments.items():\n",
    "        print(f\"  Experiments with N = {N}:\")\n",
    "        for dat in experiment_data:\n",
    "            print(f\"    Experiment data: {dat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experiment_7dof_iiwa__1_1500_0.300greedy20230908201834'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: regions 46.3 time: 5726.3\n",
      "std: regions 4.5 time: 1737.8\n"
     ]
    }
   ],
   "source": [
    "data = np.array(grouped_experiments[3][1500])\n",
    "means = data.mean(axis =0)\n",
    "std = data.std(axis =0)\n",
    "\n",
    "print(f\"mean: regions {means[0]:.1f} time: {means[2]:.1f}\")\n",
    "print(f\"std: regions {std[0]:.1f} time: {std[2]:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "experiment_directories_red = []\n",
    "for e in experiment_directories:\n",
    "    if '7dof' in e and 'greedy' in e:\n",
    "        experiment_directories_red.append(e)\n",
    "experiment_directory = experiment_directories_red[1]\n",
    "data_directory = os.path.join(experiment_directory, 'data')\n",
    "pickle_files = glob.glob(os.path.join(data_directory, '*.pkl'))\n",
    "pkl_files = os.listdir(data_directory)\n",
    "pkl_idx = np.argsort([int(s.replace('it_', '').replace('.pkl', '')) for s in pkl_files])\n",
    "\n",
    "#pickle_files.sort()\n",
    "\n",
    "last_pickle_file = data_directory+'/'+pkl_files[pkl_idx[-1]]#pickle_files[-1]#max(pickle_files, key=os.path.getctime)\n",
    "\n",
    "# Load the last pickle file\n",
    "with open(last_pickle_file, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "# print(experiment_directory)\n",
    "# with open(experiment_directory+'/cfg.yaml', 'r') as f:\n",
    "#     data  = yaml.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgraph_verts = data['vg']\n",
    "# vgraph_adj_mats= data['vad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydrake.all import MathematicalProgram, Solve, SolverOptions, CommonSolverOption\n",
    "\n",
    "def max_clique(adj_mat):\n",
    "    #assert adj_mat.shape[0] == len(graph_vertices)\n",
    "    #assert graph_vertices[0, :].shape[0] == points_to_exclude.shape[1]\n",
    "    \n",
    "    #dim = graph_vertices.shape[1]\n",
    "    #compute radius of circumscribed sphere of all points to get soft margin size\n",
    "    n = adj_mat.shape[0]\n",
    "    \n",
    "    prog = MathematicalProgram()\n",
    "    v = prog.NewBinaryVariables(n)\n",
    "    prog.AddLinearCost(-np.sum(v))\n",
    "    \n",
    "    \n",
    "    for i in range(0,n):\n",
    "        for j in range(i+1,n):\n",
    "            if adj_mat[i,j] == 0:\n",
    "                prog.AddLinearConstraint(v[i] + v[j] <= 1)\n",
    "\n",
    "    solver_options = SolverOptions()\n",
    "    solver_options.SetOption(CommonSolverOption.kPrintToConsole, 1)\n",
    "\n",
    "    result = Solve(prog, solver_options=solver_options)\n",
    "    print(result.is_success())\n",
    "    return np.where(result.GetSolution(v)==1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7dof_iiwa__34_1500_0.300greedy20230910054858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/numpy/core/fromnumeric.py:90: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "<ipython-input-50-182e59b09b09>:24: RuntimeWarning: invalid value encountered in matmul\n",
      "  prog.AddLinearConstraint((A@lam[i,:])[0] == 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBS Iteration 0\n",
      "Max clique on visibility graph has size 483\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 0\n",
      "Max clique on visibility graph has size 238\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 0\n",
      "Max clique on visibility graph has size 250\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 0\n",
      "Max clique on visibility graph has size 294\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 0\n",
      "Max clique on visibility graph has size 348\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 0\n",
      "Max clique on visibility graph has size 242\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 0\n",
      "Max clique on visibility graph has size 149\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 0\n",
      "Max clique on visibility graph has size 164\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 0\n",
      "Max clique on visibility graph has size 257\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 0\n",
      "Max clique on visibility graph has size 384\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 0\n",
      "Max clique on visibility graph has size 264\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 0\n",
      "Max clique on visibility graph has size 141\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 0\n",
      "Max clique on visibility graph has size 174\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 0\n",
      "Max clique on visibility graph has size 127\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 0\n",
      "Max clique on visibility graph has size 400\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 0\n",
      "Max clique on visibility graph has size 154\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 1\n",
      "Max clique on visibility graph has size 229\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 1\n",
      "Max clique on visibility graph has size 165\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 1\n",
      "Max clique on visibility graph has size 151\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 1\n",
      "Max clique on visibility graph has size 183\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 1\n",
      "Max clique on visibility graph has size 173\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 1\n",
      "Max clique on visibility graph has size 132\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 1\n",
      "Max clique on visibility graph has size 123\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 1\n",
      "Max clique on visibility graph has size 129\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 1\n",
      "Max clique on visibility graph has size 68\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 1\n",
      "Max clique on visibility graph has size 156\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 1\n",
      "Max clique on visibility graph has size 84\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 1\n",
      "Max clique on visibility graph has size 127\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 1\n",
      "Max clique on visibility graph has size 56\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 1\n",
      "Max clique on visibility graph has size 138\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 1\n",
      "Max clique on visibility graph has size 154\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 1\n",
      "Max clique on visibility graph has size 114\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 1\n",
      "Max clique on visibility graph has size 117\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 1\n",
      "Max clique on visibility graph has size 104\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 1\n",
      "Max clique on visibility graph has size 162\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 1\n",
      "Max clique on visibility graph has size 118\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 1\n",
      "Max clique on visibility graph has size 164\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 1\n",
      "Max clique on visibility graph has size 89\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 1\n",
      "Max clique on visibility graph has size 93\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 2\n",
      "Max clique on visibility graph has size 181\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 2\n",
      "Max clique on visibility graph has size 129\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 2\n",
      "Max clique on visibility graph has size 130\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 2\n",
      "Max clique on visibility graph has size 120\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 2\n",
      "Max clique on visibility graph has size 100\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 2\n",
      "Max clique on visibility graph has size 133\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 2\n",
      "Max clique on visibility graph has size 89\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 2\n",
      "Max clique on visibility graph has size 81\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 2\n",
      "Max clique on visibility graph has size 100\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 2\n",
      "Max clique on visibility graph has size 87\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 2\n",
      "Max clique on visibility graph has size 110\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 2\n",
      "Max clique on visibility graph has size 75\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 2\n",
      "Max clique on visibility graph has size 119\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 2\n",
      "Max clique on visibility graph has size 69\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 2\n",
      "Max clique on visibility graph has size 48\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 2\n",
      "Max clique on visibility graph has size 83\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 2\n",
      "Max clique on visibility graph has size 113\n",
      "Number of non-clique members lying in the convex hull of the clique: 1\n",
      "CBS Iteration 2\n",
      "Max clique on visibility graph has size 88\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 2\n",
      "Max clique on visibility graph has size 88\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 2\n",
      "Max clique on visibility graph has size 59\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 2\n",
      "Max clique on visibility graph has size 80\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 2\n",
      "Max clique on visibility graph has size 101\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 2\n",
      "Max clique on visibility graph has size 74\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 2\n",
      "Max clique on visibility graph has size 107\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 2\n",
      "Max clique on visibility graph has size 69\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 2\n",
      "Max clique on visibility graph has size 103\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 2\n",
      "Max clique on visibility graph has size 69\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n",
      "CBS Iteration 2\n",
      "Max clique on visibility graph has size 97\n",
      "Number of non-clique members lying in the convex hull of the clique: 0\n"
     ]
    }
   ],
   "source": [
    "print(experiment_directory.replace('logs/experiment_',''))\n",
    "from clique_covers import extend_cliques, compute_greedy_clique_partition\n",
    "clique_sizes = []\n",
    "num_vertex_holes_in_clique = []\n",
    "\n",
    "for it, (verts, admat) in enumerate(zip(data['vg'], data['vad'])):\n",
    "    cliques = compute_greedy_clique_partition(admat.toarray(), 10)\n",
    "    cliques = extend_cliques(admat.toarray(), cliques)\n",
    "    for clique in cliques:\n",
    "        #verts = vgraph_verts[0]\n",
    "        num_non_clique_verts = verts.shape[0]-len(clique)\n",
    "        non_clique_idx = np.delete(np.arange(len(verts)), clique)\n",
    "        clique_verts = verts[clique]\n",
    "        non_clique_verts = verts[non_clique_idx]\n",
    "        #def convex hull program\n",
    "        n = 0\n",
    "        for vert_of_interest in non_clique_verts:\n",
    "            prog = MathematicalProgram()\n",
    "            num_non_clique_verts = 1\n",
    "\n",
    "            lam = prog.NewContinuousVariables(num_non_clique_verts, len(clique))\n",
    "            A = np.ones((1,len(clique)))\n",
    "            for i in range(num_non_clique_verts):\n",
    "                prog.AddLinearConstraint((A@lam[i,:])[0] == 1)\n",
    "            for l in lam.flatten():\n",
    "                prog.AddLinearConstraint(l>=0)\n",
    "            #pred = lam@verts[clique]\n",
    "            for i in range(num_non_clique_verts):\n",
    "                prog.AddLinearEqualityConstraint(clique_verts.T, vert_of_interest.reshape(-1,1), lam[i,:])\n",
    "\n",
    "            #verts[non_clique_idx[i],:].reshape(-1,1)\n",
    "\n",
    "            result = Solve(prog)\n",
    "            #print(result.is_success())\n",
    "            if result.is_success():\n",
    "                n+=1\n",
    "        clique_sizes.append(len(clique))\n",
    "        num_vertex_holes_in_clique.append(n)\n",
    "        print(f\"CBS Iteration {it}\")\n",
    "        print(f\"Max clique on visibility graph has size {len(clique)}\")\n",
    "        print(f\"Number of non-clique members lying in the convex hull of the clique: {n}\")\n",
    "        #print(f\"number of verts in the convex hull of maxclique that are not in the maxclique: {n}, for clique of size {len(clique)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of cliques 67\n",
      "number of violating cliques 1\n",
      "violators (#holes/cliquesize):  1/113 \n"
     ]
    }
   ],
   "source": [
    "print(f\"number of cliques {len(clique_sizes)}\")\n",
    "print(f\"number of violating cliques {len(np.where(np.array(num_vertex_holes_in_clique)>0)[0])}\")\n",
    "ioi = np.where(np.array(num_vertex_holes_in_clique)>0)[0]\n",
    "sizes_oi = [c for c in np.array(clique_sizes)[ioi]]\n",
    "numvholes_in_clique_oi = [c for c in np.array(num_vertex_holes_in_clique)[ioi]]\n",
    "strings = [f\" {n}/{s} \" for n,s in zip(numvholes_in_clique_oi, sizes_oi)]\n",
    "s = \"\"\n",
    "for a in strings:\n",
    "    s+=a\n",
    "print(f\"violators (#holes/cliquesize): {s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of cliques 38\n",
      "number of violating cliques 5\n",
      "violators (#holes/cliquesize):  1/74  4/173  1/279  1/306  9/188 \n"
     ]
    }
   ],
   "source": [
    "print(f\"number of cliques {len(clique_sizes)}\")\n",
    "print(f\"number of violating cliques {len(np.where(np.array(num_vertex_holes_in_clique)>0)[0])}\")\n",
    "ioi = np.where(np.array(num_vertex_holes_in_clique)>0)[0]\n",
    "sizes_oi = [c for c in np.array(clique_sizes)[ioi]]\n",
    "numvholes_in_clique_oi = [c for c in np.array(num_vertex_holes_in_clique)[ioi]]\n",
    "strings = [f\" {n}/{s} \" for n,s in zip(numvholes_in_clique_oi, sizes_oi)]\n",
    "s = \"\"\n",
    "for a in strings:\n",
    "    s+=a\n",
    "print(f\"violators (#holes/cliquesize): {s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 1, 0, 0, 0, 4, 1, 0, 1, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[119, 102, 96, 97, 59, 91, 68, 41, 85, 31, 60, 44, 85, 32, 84, 15, 65, 21, 42, 41, 48, 54, 74]\n"
     ]
    }
   ],
   "source": [
    "print(num_vertex_holes_in_clique)\n",
    "print([len(c) for c in cliques])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_vertex_holes_in_clique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Expression \"(x(0,0) + x(0,1) + x(0,2) + x(0,3) + x(0,4) + x(0,5) + x(0,6) + x(0,7) + x(0,8) + x(0,9) + x(0,10) + x(0,11) + x(0,12) + x(0,13) + x(0,14) + x(0,15) + x(0,16) + x(0,17) + x(0,18) + x(0,19) + x(0,20) + x(0,21) + x(0,22) + x(0,23) + x(0,24) + x(0,25) + x(0,26) + x(0,27) + x(0,28) + x(0,29) + x(0,30) + x(0,31) + x(0,32) + x(0,33) + x(0,34) + x(0,35) + x(0,36) + x(0,37) + x(0,38) + x(0,39) + x(0,40) + x(0,41) + x(0,42) + x(0,43) + x(0,44) + x(0,45) + x(0,46) + x(0,47) + x(0,48) + x(0,49) + x(0,50) + x(0,51) + x(0,52) + x(0,53) + x(0,54) + x(0,55) + x(0,56) + x(0,57) + x(0,58) + x(0,59) + x(0,60) + x(0,61) + x(0,62) + x(0,63) + x(0,64) + x(0,65) + x(0,66) + x(0,67) + x(0,68) + x(0,69) + x(0,70) + x(0,71) + x(0,72) + x(0,73) + x(0,74) + x(0,75) + x(0,76) + x(0,77) + x(0,78) + x(0,79) + x(0,80) + x(0,81) + x(0,82) + x(0,83) + x(0,84) + x(0,85) + x(0,86) + x(0,87) + x(0,88) + x(0,89) + x(0,90) + x(0,91) + x(0,92) + x(0,93) + x(0,94) + x(0,95) + x(0,96) + x(0,97) + x(0,98) + x(0,99) + x(0,100) + x(0,101) + x(0,102) + x(0,103) + x(0,104) + x(0,105) + x(0,106) + x(0,107) + x(0,108) + x(0,109) + x(0,110) + x(0,111) + x(0,112) + x(0,113) + x(0,114) + x(0,115) + x(0,116))\">"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(A@lam[i,:])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: regions 10.4 time: 203.4\n",
      "std: regions 1.9 time: 29.0\n"
     ]
    }
   ],
   "source": [
    "data = np.array(grouped_experiments[1][1])\n",
    "means = data.mean(axis =0)\n",
    "std = data.std(axis =0)\n",
    "\n",
    "print(f\"mean: regions {means[0]:.1f} time: {means[2]:.1f}\")\n",
    "print(f\"std: regions {std[0]:.1f} time: {std[2]:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'cvx_hull' in experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "def parse_logfile(filename):\n",
    "    logfile = open(filename, 'r')\n",
    "    lines = logfile.readlines()\n",
    "    logfile.close()\n",
    "\n",
    "    iteration_data = []\n",
    "    current_iteration = {}\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith('ITERATION:'):\n",
    "            if current_iteration:\n",
    "                iteration_data.append(current_iteration)\n",
    "                current_iteration = {}\n",
    "        elif line.startswith('summary'):\n",
    "            current_iteration['summary'] = line.strip()\n",
    "        elif line.startswith('number of regions step'):\n",
    "            current_iteration['number_of_regions_step'] = int(line.split()[-1])\n",
    "        elif line.startswith('number of regions total'):\n",
    "            current_iteration['number_of_regions_total'] = int(line.split()[-1])\n",
    "        elif line.startswith('tstep'):\n",
    "            a = line.replace(',', '')\n",
    "            current_iteration['tstep'] = float(a.split()[1])\n",
    "            current_iteration['t_total'] = float(a.split()[3])\n",
    "        elif line.startswith('tsample'):\n",
    "            a = line.replace(',', '')\n",
    "            current_iteration['tsample'] = float(a.split()[1])\n",
    "            current_iteration['t_visgraph'] = float(a.split()[3])\n",
    "        elif line.startswith('t_mhs'):\n",
    "            current_iteration['t_mhs'] = float(line.split()[1])\n",
    "        elif line.startswith('t_regions'):\n",
    "            current_iteration['t_regions'] = float(line.split()[1])\n",
    "        elif line.startswith('coverage'):\n",
    "            current_iteration['coverage'] = float(line.split()[1])\n",
    "        elif '[VisSeeder] Coverage met, terminated' in line:\n",
    "            current_iteration['termination'] = line.strip()\n",
    "\n",
    "    if current_iteration:\n",
    "        iteration_data.append(current_iteration)\n",
    "    return iteration_data\n",
    "\n",
    "\n",
    "logs_directory = '../logs'\n",
    "\n",
    "# Get a list of all subdirectories in the logs directory\n",
    "experiment_directories = [directory for directory in glob.glob(os.path.join(logs_directory, '*')) if os.path.isdir(directory)]\n",
    "\n",
    "# Define a dictionary to store the grouped experiments\n",
    "grouped_experiments = {}\n",
    "\n",
    "# Iterate over each experiment directory\n",
    "for experiment_directory in experiment_directories:\n",
    "    # Parse the experiment name\n",
    "    experiment_name = os.path.basename(experiment_directory)\n",
    "    name_parts = experiment_name.split('_')\n",
    "    \n",
    "    # Extract the relevant values from the experiment name\n",
    "    if '5dof_ur_naive' in experiment_name:\n",
    "        b = 1  #int(name_parts[-5])\n",
    "    else:\n",
    "        continue\n",
    "    N = int(name_parts[-3])\n",
    "    \n",
    "    # Get the last pickle file in the 'data' subdirectory\n",
    "    data_directory = os.path.join(experiment_directory, 'data')\n",
    "    pickle_files = glob.glob(os.path.join(data_directory, '*.pkl'))\n",
    "    pkl_files = os.listdir(data_directory)\n",
    "    pkl_idx = np.argsort([int(s.replace('it_', '').replace('.pkl', '')) for s in pkl_files])\n",
    "    \n",
    "    #pickle_files.sort()\n",
    "    \n",
    "    last_pickle_file = data_directory+'/'+pkl_files[pkl_idx[-1]]#pickle_files[-1]#max(pickle_files, key=os.path.getctime)\n",
    "    \n",
    "    # Load the last pickle file\n",
    "    with open(last_pickle_file, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    \n",
    "    # Find the 'summar' subdirectory and get the path to the text file\n",
    "    summar_directory = os.path.join(experiment_directory, 'summary')\n",
    "    text_files = glob.glob(os.path.join(summar_directory, '*.txt'))\n",
    "    last_text_file = max(text_files, key=os.path.getctime)\n",
    "    \n",
    "\n",
    "    iteration_dictionaries = parse_logfile(last_text_file)\n",
    "    tsample = np.sum([i['tsample'] for i in iteration_dictionaries[1:]])\n",
    "    tvis = np.sum([i['t_visgraph'] for i in iteration_dictionaries[1:]])\n",
    "    tmhs = np.sum([i['t_mhs'] for i in iteration_dictionaries[1:]])\n",
    "    tregions = np.sum([i['t_regions'] for i in iteration_dictionaries[1:]])\n",
    "    # # Read the last line of the text file to extract coverage\n",
    "    # with open(last_text_file, 'r') as file:\n",
    "    #     lines = file.readlines()\n",
    "    #     last_line = lines[-1].strip()\n",
    "    #     coverage = float(last_line.split()[1])\n",
    "\n",
    "    # Group experiments by 'b' value\n",
    "    if b not in grouped_experiments:\n",
    "        grouped_experiments[b] = {}\n",
    "    \n",
    "    # Group experiments by 'N' value\n",
    "    if N not in grouped_experiments[b]:\n",
    "        grouped_experiments[b][N] = []\n",
    "    \n",
    "    # Add the experiment data to the grouped experiments dictionary\n",
    "    grouped_experiments[b][N].append([\n",
    "            np.sum(len(g) for g in data['rb']), data['cov'] , data['ttotal'], tsample, tvis, tmhs, tregions])\n",
    "\n",
    "# Print the grouped experiments\n",
    "for b, experiments in grouped_experiments.items():\n",
    "    print(f\"Experiments with b = {b}:\")\n",
    "    for N, experiment_data in experiments.items():\n",
    "        print(f\"  Experiments with N = {N}:\")\n",
    "        for dat in experiment_data:\n",
    "            print(f\"    Experiment data: {dat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(grouped_experiments[1][1])\n",
    "means = data.mean(axis =0)\n",
    "std = data.std(axis =0)\n",
    "\n",
    "print(f\"mean: regions {means[0]:.1f} time: {means[2]:.1f}\")\n",
    "print(f\"std: regions {std[0]:.1f} time: {std[2]:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples used in all tests 5000\n",
      "#######################################################\n",
      "Experiment Village\n",
      "Two sided bernoulli test 95% confidence coverage lies between 0.811 and 0.789\n",
      "One sided bernoulli test: 95% confidence coverage lies above 0.791 \n",
      "Experiment 3dof\n",
      "Two sided bernoulli test 95% confidence coverage lies between 0.908 and 0.892\n",
      "One sided bernoulli test: 95% confidence coverage lies above 0.893 \n",
      "Experiment 5dof\n",
      "Two sided bernoulli test 95% confidence coverage lies between 0.762 and 0.738\n",
      "One sided bernoulli test: 95% confidence coverage lies above 0.740 \n",
      "Experiment 7dof\n",
      "Two sided bernoulli test 95% confidence coverage lies between 0.713 and 0.687\n",
      "One sided bernoulli test: 95% confidence coverage lies above 0.689 \n"
     ]
    }
   ],
   "source": [
    "# bernoulli test\n",
    "from scipy.special import comb\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "alpha_0 = 0.8\n",
    "alpha_z = 0.05\n",
    "n = 5000\n",
    "names = ['Village', '3dof', '5dof', '7dof']\n",
    "cov_thr = [0.8, 0.9, 0.75, 0.7]\n",
    "print(f\"Number of samples used in all tests {n}\")\n",
    "print(f\"#######################################################\")\n",
    "\n",
    "for na, alpha_0 in zip(names,cov_thr):\n",
    "    #norm_approx_cdf(0.75*n,n, alpha_0)\n",
    "    mu = n*alpha_0\n",
    "    sigma= np.sqrt(n*alpha_0*(1-alpha_0))\n",
    "    #print(sum)\n",
    "    #twosided\n",
    "    top =norm.ppf(0.025, loc = mu, scale= sigma)/n\n",
    "    bottom = norm.ppf(0.975, loc = mu, scale= sigma)/n \n",
    "    print(f\"Experiment {na}\")\n",
    "    print(f\"Two sided bernoulli test 95% confidence coverage lies between {bottom:.3f} and {top:.3f}\")\n",
    "    #onesided\n",
    "    print(f\"One sided bernoulli test: 95% confidence coverage lies above {norm.ppf(0.05, loc = mu, scale= sigma)/n:.3f} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8110872305947975"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_0 = 0.8\n",
    "n = 5000\n",
    "mu = n*alpha_0\n",
    "sigma= np.sqrt(n*alpha_0*(1-alpha_0))\n",
    "norm.ppf(0.975, loc = mu, scale = sigma)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3436.489908189888"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.ppf(0.025, loc = mu, scale= sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.int(np.ceil(alpha*n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-bd605933da88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "range(np.int(np.ceil(alpha*n)), n+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
